# https://github.com/ray-project/ray/blob/master/rllib/tuned_examples/a3c/pong-a3c.yaml
# This gets to ~19-20 reward in ~30 minutes / 4m steps on a m4.10xl instance
# TODO(rliaw): this has regressed in performance
pong-a3c:
    env: PongDeterministic-v4
    run: A3C
    config:
        # Works for both torch and tf.
        framework: tf2
        num_workers: 16
        rollout_fragment_length: 20
        vf_loss_coeff: 0.5
        entropy_coeff: 0.01
        gamma: 0.99
        grad_clip: 40.0
        lambda: 1.0
        lr: 0.0001
        observation_filter: NoFilter
        preprocessor_pref: rllib
        model:
            use_lstm: true
            conv_activation: elu
            dim: 42
            grayscale: true
            zero_mean: false
            # Reduced channel depth and kernel size from default
            conv_filters: [
                [32, [3, 3], 2],
                [32, [3, 3], 2],
                [32, [3, 3], 2],
                [32, [3, 3], 2],
            ]
    local_dir: PongDeterministic-v4
    checkpoint_freq: 2
    keep_checkpoints_num: 3

# rllib train -f examples/yaml_files/pong-a3c.yaml
# tensorboard --bind_all --port=12301 --logdir /home/ppirog/projects/rllib_examples/PongDeterministic-v4
# kill $(ps -e | grep 'tensorboard' | awk '{print $1}')
# # web browser address: http://212.109.128.252:12301/#scalars